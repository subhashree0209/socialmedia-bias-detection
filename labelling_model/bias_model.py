# -*- coding: utf-8 -*-
"""fullfinetuned_roberta_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wddKQVNbXYrsTxbn5lZQbVJKcs9Op-tW

# Finetuning roBERTa for Political Media Bias Detection

## Step 1: Data pre-processing

### Import packages & libraries
"""

pip install transformers datasets torch scikit-learn pandas

pip install --upgrade wandb --upgrade transformers

import numpy as np
import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from transformers import RobertaForSequenceClassification, RobertaTokenizer
from transformers import BertTokenizer
from datasets import Dataset
from transformers import BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.utils.class_weight import compute_class_weight
from peft import LoraConfig, get_peft_model
from google.colab import drive
drive.mount('/content/drive')

"""### Load & inspect dataset"""

# load labeled data (for training and TV split)
labeled_data_path = '/content/drive/My Drive/dsa3101/labelled_data_clean.csv'
df_labelled = pd.read_csv(labeled_data_path)

# check the first few rows of data
df_labelled.head(10)

# check the unique values in the 'Label' column and their counts
label_counts = df_labelled['bias_text'].value_counts()

# display the unique labels and their counts
print(label_counts)

# clean the 'body' column to ensure all entries are strings
df_labelled['body'] = df_labelled['body'].fillna('').astype(str)

# load unlabelled data (for prediction)
unlabelled_data_path = '/content/drive/My Drive/dsa3101/unlabelled_data_clean.csv'
df_unlabelled = pd.read_csv(unlabelled_data_path)

# check the first few rows of data
df_unlabelled.head(10)

"""## Step 2: Tokenize the text and prepare the data for roBERTa"""

# load the roBERTa tokenizer
tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

# preprocess function to tokenize text (using 'body' column)
def preprocess_function(examples):
    return tokenizer(examples['body'], truncation=True, padding=True, max_length=256)

# create label mapping
print("\nActual labels in dataset:")
print(df_labelled['bias_text'].unique())

label_mapping = {'center': 0, 'left': 1, 'right': 2}

# encode labels to integers
df_labelled['labels'] = df_labelled['bias_text'].map(label_mapping)

# Ccnvert to int
df_labelled['labels'] = df_labelled['labels'].astype(int)

print("\nMapped label distribution:")
print(df_labelled['labels'].value_counts().sort_index())

"""## Step 3: TV Split"""

# split the labeled data into train and validation sets
train_df, val_df = train_test_split(
    df_labelled,
    test_size=0.15,
    random_state=42,
    stratify=df_labelled['labels']
)

print(f"\nTrain set size: {len(train_df)}")
print("Train label distribution:")
print(train_df['labels'].value_counts().sort_index())

print(f"\nValidation set size: {len(val_df)}")
print("Validation label distribution:")
print(val_df['labels'].value_counts().sort_index())

# convert pandas DataFrame to Hugging Face Dataset format
train_dataset = Dataset.from_pandas(train_df[['body', 'labels']])
val_dataset = Dataset.from_pandas(val_df[['body', 'labels']])

# tokenize the datasets
train_dataset = train_dataset.map(preprocess_function, batched=True)
val_dataset = val_dataset.map(preprocess_function, batched=True)

# set format for PyTorch (IMPORTANT: includes 'labels')
train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])

# for the unlabeled dataset, tokenize the 'body' column
df_unlabelled['body'] = df_unlabelled['body'].apply(str)
unlabeled_dataset = Dataset.from_pandas(df_unlabelled[['body']])
unlabeled_dataset = unlabeled_dataset.map(preprocess_function, batched=True)
unlabeled_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])

# check tokenized output (optional)
print("\nTokenized Train Dataset Example:")
print(train_dataset[0])

decoded_text = tokenizer.decode(train_dataset[0]['input_ids'])
print(f"\nDecoded text preview: {decoded_text[:200]}...")

"""## Step 4: Compute class weights and use custom trainer"""

# compute class weights since classes/ labels are imbalanced
print("COMPUTING CLASS WEIGHTS")

class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(train_df['labels']),
    y=train_df['labels']
)
class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)

print(f"\nClass weights (to handle imbalance):")
for i, weight in enumerate(class_weights):
    print(f"  Class {i}: {weight:.4f}")

# custom trainer with weighted classes/ labels
class WeightedTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits

        # apply class weights to loss
        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor.to(logits.device), label_smoothing=0.1)
        loss = loss_fct(logits, labels)

        return (loss, outputs) if return_outputs else loss

# eval metrics function
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    preds = predictions.argmax(axis=1)

    # overall metrics only
    acc = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds, average='weighted')
    precision = precision_score(labels, preds, average='weighted')
    recall = recall_score(labels, preds, average='weighted')

    # optional: prediction distribution
    unique, counts = np.unique(preds, return_counts=True)
    print(f"\n Prediction distribution: {dict(zip(unique, counts))}")

    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Step 5: Full Finetune RoBERTa"""

# load roBERTa model
num_labels = len(df_labelled['labels'].unique())
print(f"\nNumber of classes: {num_labels}")



model = RobertaForSequenceClassification.from_pretrained(
    'roberta-base',
    num_labels=num_labels,
    problem_type="single_label_classification",
    hidden_dropout_prob=0.3,           # ADD THIS
    attention_probs_dropout_prob=0.3,  # ADD THIS
)

# finetuning parameters
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=10,                  # longer training for full convergence
    per_device_train_batch_size=16,       # larger batch size improves stability
    per_device_eval_batch_size=32,        # faster evaluation
    learning_rate=1e-5,                   # lower LR for stable fine-tuning
    warmup_ratio=0.1,                     # small warmup helps convergence
    weight_decay=0.1,                    # standard weight decay
    logging_strategy="epoch",             # only log per epoch
    eval_strategy="epoch",                # evaluate per epoch
    save_strategy="epoch",                # save per epoch
    save_total_limit=3,                   # keep 3 best checkpoints
    load_best_model_at_end=True,          # automatically load best model
    metric_for_best_model="f1",           # optimize for F1 score
    greater_is_better=True,
    report_to="none",
    seed=42,
    fp16=torch.cuda.is_available(),       # use mixed precision if GPU supports
    gradient_accumulation_steps=2,        # larger effective batch possible
    dataloader_num_workers=2,             # speed up data loading
    remove_unused_columns=False,          # avoid data loss
)

# initialise weighted trainer
trainer = WeightedTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
)

# start training
trainer.train()

# save model to gdrive
model.save_pretrained('/content/drive/My Drive/dsa3101/bias_detection_model_roberta')
tokenizer.save_pretrained('/content/drive/My Drive/dsa3101/bias_detection_model_roberta')

print("\n✓ Model and tokenizer saved to Google Drive!")

"""## Step 6: Evaluate model performance"""

# load saved model and tokenizer from the given path
model_path = '/content/drive/My Drive/dsa3101/bias_detection_model_roberta'

model = RobertaForSequenceClassification.from_pretrained(model_path)
tokenizer = RobertaTokenizer.from_pretrained(model_path)

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=10,                  # longer training for full convergence
    per_device_train_batch_size=16,       # larger batch size improves stability
    per_device_eval_batch_size=32,        # faster evaluation
    learning_rate=1e-5,                   # lower LR for stable fine-tuning
    warmup_ratio=0.1,                     # small warmup helps convergence
    weight_decay=0.1,                     # standard weight decay
    logging_strategy="epoch",             # only log per epoch
    eval_strategy="epoch",                # evaluate per epoch
    save_strategy="epoch",                # save per epoch
    save_total_limit=3,                   # keep 3 best checkpoints
    load_best_model_at_end=True,          # automatically load best model
    metric_for_best_model="f1",           # optimize for F1 score
    greater_is_better=True,
    report_to="none",
    seed=42,
    fp16=torch.cuda.is_available(),       # use mixed precision if GPU supports
    gradient_accumulation_steps=2,        # larger effective batch possible
    dataloader_num_workers=2,             # speed up data loading
    remove_unused_columns=False,          # avoid data loss
)

# prepare the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]
)

# final evaluation on the validation set
print("FINAL EVALUATION")
results = trainer.evaluate()
print("\nEvaluation Results:", results)


# Get predictions on the validation set
predictions = trainer.predict(val_dataset)
preds = predictions.predictions.argmax(axis=1)

# validation set prediction distribution
print("\nValidation set PREDICTION distribution:")
unique, counts = np.unique(preds, return_counts=True)
for label, count in zip(unique, counts):
    percentage = count / len(preds) * 100
    print(f"  Class {label}: {count} ({percentage:.1f}%)")

# validation set true label distribution
print("\nValidation set TRUE label distribution:")
true_labels = val_df['labels'].values
unique, counts = np.unique(true_labels, return_counts=True)
for label, count in zip(unique, counts):
    percentage = count / len(true_labels) * 100
    print(f"  Class {label}: {count} ({percentage:.1f}%)")

# get predictions for the unlabeled dataset using the trained model
predictions_unlabeled = trainer.predict(unlabeled_dataset)  # Use `trainer` to predict
predicted_labels = predictions_unlabeled.predictions.argmax(axis=1)
predicted_probs = torch.softmax(torch.tensor(predictions_unlabeled.predictions), dim=1).numpy()

# add predicted labels to the dataframe
df_unlabelled['predicted_label'] = [reverse_label_mapping[label] for label in predicted_labels]

# add confidence scores (the max probability for each prediction)
df_unlabelled['confidence'] = predicted_probs.max(axis=1)

# add probabilities for each class (left, center, right)
for i, label_name in enumerate(['left', 'center', 'right']):
    df_unlabelled[f'prob_{label_name}'] = predicted_probs[:, i]

# display the dataframe with the predictions and additional information
print("\nDataFrame with Predictions:")
print(df_unlabelled[['body', 'predicted_label', 'confidence', 'prob_left', 'prob_center', 'prob_right']].head(10))  # Print first 10 rows

# save predictions to a CSV file
df_unlabelled.to_csv('/content/drive/My Drive/dsa3101/fullfinetuned_valtest_predictions.csv', index=False)
print("\n✓ Predictions saved to 'predictions.csv'!")

"""## Step 7: Make predictions on unlabelled data"""

# load the saved model and tokenizer
model_path = '/content/drive/My Drive/dsa3101/bias_detection_model_roberta'
model = RobertaForSequenceClassification.from_pretrained(model_path)
tokenizer = RobertaTokenizer.from_pretrained(model_path)

# prepare the trainer
trainer = Trainer(
    model=model,
    args=training_args,  # Use the same training arguments you used previously
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]
)

# make predictions on the unlabeled dataset
predictions_unlabeled = trainer.predict(unlabeled_dataset)
predicted_labels = predictions_unlabeled.predictions.argmax(axis=1)
predicted_probs = torch.softmax(torch.tensor(predictions_unlabeled.predictions), dim=1).numpy()

# convert back to label names (assuming label_mapping is defined)
reverse_label_mapping = {v: k for k, v in label_mapping.items()}
df_unlabelled['predicted_label'] = [reverse_label_mapping[label] for label in predicted_labels]

# add confidence scores (the max probability for each prediction)
df_unlabelled['confidence'] = predicted_probs.max(axis=1)

# add probabilities for each class (neutral, left, right)
for i, label_name in enumerate(['neutral', 'left', 'right']):
    df_unlabelled[f'prob_{label_name}'] = predicted_probs[:, i]

# show prediction distribution
print("\nPrediction distribution on unlabeled data:")
print(df_unlabelled['predicted_label'].value_counts())

# show the average confidence
print(f"\nAverage confidence: {df_unlabelled['confidence'].mean():.4f}")

# Save predictions to CSV
df_unlabelled.to_csv('/content/drive/My Drive/dsa3101/fullfinetuned_unlabelled_predictions.csv', index=False)
print("\n✓ Predictions saved to 'predictions.csv'!")

# show some sample predictions
print("\nSample predictions:")
print(df_unlabelled[['body', 'predicted_label', 'confidence']].head(10))